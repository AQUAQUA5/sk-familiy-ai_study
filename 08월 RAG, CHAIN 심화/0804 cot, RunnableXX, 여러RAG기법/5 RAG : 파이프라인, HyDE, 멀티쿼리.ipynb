{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cac8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 파이프라인\n",
    "# !pip install langchain_chroma\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_spliter.split_documents(documents)\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "db = Chroma.from_documents(split_documents, embedding)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    '''\n",
    "    다음 문맥만을 고려해서 질문에 답하시요.\n",
    "\n",
    "\n",
    "    문맥: \"\"\"{context}\"\"\"\n",
    "   \n",
    "    질문: {question}\n",
    "    '''\n",
    ")\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "chain = {\n",
    "    \"question\" : RunnablePassthrough(),\n",
    "    \"context\" : retriever,\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "output = chain.invoke(\"LangChain 개요를 알려줘?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyDE RAG\n",
    "hypothetical_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "다음 질문에 한 문장으로 답할 것!\n",
    "질문 : {question}\n",
    "\"\"\")\n",
    "hypothetical_chain = hypothetical_prompt | model | StrOutputParser()\n",
    "\n",
    "hype_rag_chain = {\n",
    "    \"question\" : RunnablePassthrough(),\n",
    "    \"context\" : hypothetical_chain |  retriever,\n",
    "} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Multi-Query RAG\n",
    "from pydantic import BaseModel, Field\n",
    "class QueryGenerationOutput(BaseModel):\n",
    "    queries: list[str] = Field(description='검색 쿼리 목록')\n",
    "query_generation_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "질문에 대해 벡터 데이터베이스에서 관련 문서를 검색하기 위한 3개의 서로 다른 검색 쿼리를 생성하세요.\n",
    "거리 기반 유사성 검색의 한계를 극복하기 위해 사용자의 질문에 대해서 여러 관점을 제공하는 것이 목표입니다.\n",
    "질문: {question}\n",
    "\"\"\")\n",
    "\n",
    "query_generation_chain = (\n",
    "    query_generation_prompt\n",
    "    | model.with_structured_output(QueryGenerationOutput)\n",
    "    | (lambda x : x.queries)\n",
    ")\n",
    "\n",
    "multi_query_rag_chain = {   \"question\" : RunnablePassthrough(),\n",
    "    'context': query_generation_chain | retriever.map(),\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "output = multi_query_rag_chain.invoke(\"LangChain 개요를 알려줘?\")\n",
    "pprint.pprint(output)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
