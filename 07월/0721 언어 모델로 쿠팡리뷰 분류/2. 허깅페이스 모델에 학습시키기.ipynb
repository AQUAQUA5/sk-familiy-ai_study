{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e47b76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2362ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://admin:admin@222.112.208.67:27017')\n",
    "db = client['classification']\n",
    "documents = db['milk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8133434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우유 : 0 \n",
    "# 우유 데이터 담기 \n",
    "milk_list = []\n",
    "for x in documents.find({}, {'_id':0, 'content':1}):\n",
    "    # print(x)\n",
    "    # break\n",
    "    milk_list.append(x['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1313cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계란 : 1 \n",
    "# 계란 데이터 담기 \n",
    "documents = db['egg']\n",
    "egg_list = []\n",
    "for x in documents.find({}, {'_id':0, 'content':1}):\n",
    "    # print(x)\n",
    "    # break\n",
    "    egg_list.append(x['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab03e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생수 : 2 \n",
    "# 생수 데이터 담기 \n",
    "documents = db['water']\n",
    "water_list = []\n",
    "for x in documents.find({}, {'_id':0, 'content':1}):\n",
    "    # print(x)\n",
    "    # break\n",
    "    water_list.append(x['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30c6036b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'곰곰 신선한 1A 우유 2.3L 제품은 대용량이면\\n서도 품질이 좋아서 가성비 면에서 만족스럽고 \\n맛도 깔끔하면서 고소해서 매번 두 개씩 넉넉하\\n게 구입해서 냉장고에 채워두고 꾸준히 마시고 \\n\\n있는 제품입니다 우유를 자주 섭취하면 단순히 \\n배를 채우는 용도 외에도 우리 몸에 다양한 영양\\n소를 고르게 공급할 수 있어 성장기 아이나 어른 \\n모두에게 도움이 되며 특히 칼슘이 풍부하게 들\\n\\n어 있어서 뼈 건강을 유지하고 골밀도를 높이는 \\n데 큰 역할을 하기 때문에 평소 칼슘 섭취가 부\\n족하기 쉬운 현대인들에게는 꼭 필요한 식품 중 \\n하나입니다 또한 단백질도 균형 있게 함유되어 \\n\\n있어 근육 유지나 세포 재생에도 도움이 되고 비\\n타민 B군이 풍부해서 피로 회복이나 면역력 증\\n진에도 긍정적인 영향을 줍니다 곰곰 1A 등급 \\n우유는 국내산 원유를 사용한 제품으로 신선도\\n\\n도 뛰어나며 유통기한이 넉넉해서 보관 걱정 없\\n이 천천히 마실 수 있는 점도 좋았고 맛 자체도 \\n비리지 않아서 아이는 물론 우유에 예민한 어른\\n들도 거부감 없이 마실 수 있었으며 시리얼이나\\n\\n요리, 베이킹 등 다양한 활용이 가능해 아침에 \\n간단하게 한 잔씩 마시거나 요리에 곁들이기에\\n도 아주 유용합니다 특히 2.3리터 대용량이기 \\n때문에 여러 명이 함께 마시기에도 충분하고 자\\n\\n주 마시는 집에서는 번거롭게 자주 사지 않아도\\n되어서 좋았고 곰곰 브랜드 자체가 신선식품에\\n서 믿을 수 있는 퀄리티를 유지하는 편이라 아이\\n가 먹을 우유로도 안심하고 선택할 수 있는 제품\\n\\n입니다 우유의 풍부한 영양 덕분에 매일 한두 잔\\n씩 꾸준히 마시는 습관만으로도 뼈 건강은 물론 \\n전반적인 신체 컨디션 관리에 도움이 된다고 느\\n끼며 앞으로도 계속해서 구매 의사가 있는 만족\\n도 높은 우유입니다'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milk_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db160c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "re.sub(r\"[\\n]\", ' ', water_list[0])\n",
    "# re.sub(r\"[^가-힣\\sa-zA-Z]\", '', water_list[0])\n",
    "\n",
    "\n",
    "milk_list2 = list(map(lambda x : re.sub(r\"[\\n]\", ' ', x), milk_list))\n",
    "\n",
    "milk_list2 = list(map(lambda x : re.sub(r\"[^가-힣\\sa-zA-Z0-9.]\", ' ', x), milk_list2))\n",
    "\n",
    "egg_list2 = list(map(lambda x : re.sub(r\"[\\n]\", ' ', x), egg_list))\n",
    "egg_list2 = list(map(lambda x : re.sub(r\"[^가-힣\\sa-zA-Z0-9.]\", ' ', x), egg_list2))\n",
    "\n",
    "water_list2 = list(map(lambda x : re.sub(r\"[\\n]\", ' ', x), water_list))\n",
    "water_list2 = list(map(lambda x : re.sub(r\"[^가-힣\\sa-zA-Z0-9.]\", ' ', x), water_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad6e24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = milk_list2[:1000] + egg_list2[:1000] + water_list2[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40504a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [0] * 1000 + [1] * 1000 + [2] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2312ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'sentence' : data_text,\n",
    "    'label' : label\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b14fd62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/miniconda3/envs/sk_dnn1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict(data_dict)\n",
    "dataset2 = dataset.train_test_split(\n",
    "    test_size=0.2, \n",
    "    shuffle=True,\n",
    "    # stratify_by_column='label'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7d1dcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    803\n",
       "1    799\n",
       "0    798\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df =dataset2['train'].to_pandas()\n",
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2617502b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model_id = 'klue/roberta-base'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "458bd18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e07907af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2400/2400 [00:01<00:00, 2377.61 examples/s]\n",
      "Map: 100%|██████████| 600/600 [00:00<00:00, 4530.28 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset2['train']\n",
    "test_dataset = dataset2['test']\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b01a5b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38462/1785654423.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "    \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dfe190",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3859081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sk_dnn1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
