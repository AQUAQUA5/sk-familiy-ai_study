{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b1d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import os\n",
    "os.environ[\"OCR_AGENT\"] = \"pytesseract\"  # 꼭 partition_pdf 임포트 전에\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_elements(path, fname):\n",
    "    return partition_pdf(\n",
    "        filename=path + fname,\n",
    "        extract_images_in_pdf=True,  # PDF에서 이미지를 추출\n",
    "        infer_table_structure=True,  # 테이블 구조를 추론\n",
    "        chunking_strategy=\"by_title\",  # 타이틀을 기준으로 텍스트를 블록으로 분할\n",
    "        max_characters=4000,  # 최대 4000자로 텍스트 블록을 제한\n",
    "        new_after_n_chars=3800,  # 3800자 이후에 새로운 블록 생성\n",
    "        combine_text_under_n_chars=2000,  # 2000자 이하의 텍스트는 결합\n",
    "        image_output_dir_path=path,  # 이미지가 저장될 경로 설정\n",
    "   languages=['kor']\n",
    "        # image_output_dir_path=os.path.join(os.getcwd(),\"figures\"),\n",
    "    )\n",
    "raw_data = extract_pdf_elements(\"./data/\", \"RRF.pdf\")\n",
    "def categorize_elements(raw_pdf_elements):\n",
    "    \"\"\"\n",
    "    PDF에서 추출한 요소들을 테이블과 텍스트로 분류합니다.\n",
    "    raw_pdf_elements: unstructured.documents.elements 리스트\n",
    "    \"\"\"\n",
    "    tables = []\n",
    "    texts = []\n",
    "    for element in raw_pdf_elements:\n",
    "        if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "            tables.append(str(element))  # 테이블 요소를 저장\n",
    "        elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "            texts.append(str(element))  # 텍스트 요소를 저장\n",
    "    return texts, tables\n",
    "\n",
    "texts, tables = categorize_elements(raw_data)\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=2000, chunk_overlap=200\n",
    ")\n",
    "joined_texts = \" \".join(texts)\n",
    "text_token = text_splitter.split_text(joined_texts)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
