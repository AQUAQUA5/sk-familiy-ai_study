{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3496521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7155b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths= (\"https://news.naver.com/section/101\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"sa_text\", \"sa_item_SECTION_HEADLINE\")\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a90defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b702467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs) # text_splitter < 다시저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c4f8237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in /home/godldy73/miniconda3/envs/openai/lib/python3.12/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /home/godldy73/miniconda3/envs/openai/lib/python3.12/site-packages (from rank_bm25) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64489e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={\"k\" : 1, \"fetch_k\" : 4}\n",
    ")\n",
    "# 앙상블로 한거구나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f9dfb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "\n",
    "bm25_retriever.k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc985699",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, retriever], # 앙상블 써서 각각의 결과값에 가중치를 줘서 사용\n",
    "                weights=[0.2, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "425988df",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ensemble_retriever.invoke(\"삼일회계법인,pwc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "962b5961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://news.naver.com/section/101'}, page_content='지난 2년 동안 국내 시가총액 상위 100대 기업의 주주환원 규모가 35% 이상 증가한 것으로 나타났다. 특히 KT&G는 시가총액 대비 주주환원 비율에서 1위를 기록했다. 6일 기업데이터연구소 CEO스코어에 따르면 \\n\\n\\n한경비즈니스\\n\\n25분전'),\n",
       " Document(metadata={'source': 'https://news.naver.com/section/101'}, page_content='문화일보\\n\\n25분전\\n\\n\\n\\n\\n\\n\\n\\n\\n2년 새 35% 늘어난 주주환원...KT&G, 시총 대비 환원율 1위')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13762fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01d6ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 AI 언어 모델 조수입니다. 당신의 임무는 주어진 사용자 질문에 대해 벡터 데이터베이스에서 관련 문서를 검색할 수 있도록 다섯 가지 다른 버전을 생성하는 것입니다.\n",
    "사용자 질문에 대한 여러 관점을 생성함으로써, 거리 기반 유사성 검색의 한계를 극복하는 데 도움을 주는 것이 목표입니다.\n",
    "각 질문은 새 줄로 구분하여 제공하세요. 원본 질문: {question}\n",
    "\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cdf2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | ChatOpenAI(model_name = \"chatgpt-4o-latest\", temperature=0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x : x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8073a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b0216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(results, k=60, top_n=2):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(docs)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "   \n",
    "    reranked_results = [ (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x : x[1], reverse=True)\n",
    "    ]\n",
    "    return reranked_results[:top_n]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chain = generate_queries | ensemble_retriever.map() | reciprocal_rank_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "962175b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "template = \"\"\"다음 맥락을 바탕으로 질문에 답변할 것\n",
    "{context}\n",
    "\n",
    "\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e3b04b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4765/1710383296.py:11: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  reranked_results = [ (loads(doc), score)\n",
      "/tmp/ipykernel_4765/2910983370.py:25: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(\"./output.mp3\")\n"
     ]
    }
   ],
   "source": [
    "final_chain = (\n",
    "    {\n",
    "        \"context\" : chain,\n",
    "        \"question\" : RunnablePassthrough()\n",
    "    }\n",
    "    | prompt | ChatOpenAI(model_name=\"chatgpt-4o-latest\", temperature=0)\n",
    "    | StrOutputParser()\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "rt = final_chain.invoke(\"오늘의 증시\")\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"onyx\",\n",
    "    input=rt\n",
    "    )\n",
    "\n",
    "\n",
    "response.stream_to_file(\"./output.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9faf4b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/godldy73/miniconda3/envs/openai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d72c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_elements(path, fname):\n",
    "    return partition_pdf(\n",
    "        filename=path + fname,\n",
    "        extract_images_in_pdf=True,  # PDF에서 이미지를 추출\n",
    "        infer_table_structure=True,  # 테이블 구조를 추론\n",
    "        chunking_strategy=\"by_title\",  # 타이틀을 기준으로 텍스트를 블록으로 분할\n",
    "        max_characters=4000,  # 최대 4000자로 텍스트 블록을 제한\n",
    "        new_after_n_chars=3800,  # 3800자 이후에 새로운 블록 생성\n",
    "        combine_text_under_n_chars=2000,  # 2000자 이하의 텍스트는 결합\n",
    "        image_output_dir_path=path,  # 이미지가 저장될 경로 설정\n",
    "        # image_output_dir_path=os.path.join(os.getcwd(),\"figures\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = extract_pdf_elements(\"../data/\", \"최민석_자기소개서_.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
